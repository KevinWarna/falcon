{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup trainnig code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Training images 60000, Test images 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_model, self).__init__()\n",
    "    self.layer1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer3 = nn.Linear(800, 500, bias=True)\n",
    "    self.layer4 = nn.Linear(500, 10, bias=True)\n",
    "\n",
    "    self.act = nn.ReLU()\n",
    "    self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.act(self.layer1(x))\n",
    "    out = self.pool(out)\n",
    "    out = self.act(self.layer2(out))\n",
    "    out = self.pool(out)\n",
    "    out = out.view(-1, 800)\n",
    "    out = self.act(self.layer3(out))\n",
    "    out = self.act(self.layer4(out))\n",
    "    return out\n",
    "\n",
    "  def output(self, x):\n",
    "    out1 = self.act(self.layer1(x))\n",
    "    out1 = self.pool(out1)\n",
    "    out2 = self.act(self.layer2(out1))\n",
    "    out2 = self.pool(out2)\n",
    "    out2 = out2.view(-1, 800)\n",
    "    out3 = self.act(self.layer3(out2))\n",
    "    out4 = self.act(self.layer4(out3))    \n",
    "    return out1, out2, out3, out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model(\n",
      "  (layer1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer3): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (layer4): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DEVICE=\"cpu\"\n",
    "\n",
    "model = mnist_model().to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.to(DEVICE)), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 67.61333333333333, test accuracy 67.73\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 78.3, test accuracy 78.35\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 79.22666666666667, test accuracy 79.16\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 79.36, test accuracy 79.24\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 79.58666666666667, test accuracy 79.44\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 79.83333333333333, test accuracy 79.53\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 79.96, test accuracy 79.69\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 79.97666666666667, test accuracy 79.65\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 80.03333333333333, test accuracy 79.73\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 80.115, test accuracy 79.76\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 80.18333333333334, test accuracy 79.76\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 80.20833333333333, test accuracy 79.84\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 80.20166666666667, test accuracy 79.84\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 80.21833333333333, test accuracy 79.84\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 80.23, test accuracy 79.84\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    # print(img.shape, label.shape)\n",
    "    out = model(img.to(DEVICE))\n",
    "    # print(out.shape)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.to(DEVICE))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (20, 1, 5, 5)\n",
      "Layer layer1, type bias, shape (20,)\n",
      "Layer layer2, type weight, shape (50, 20, 5, 5)\n",
      "Layer layer2, type bias, shape (50,)\n",
      "Layer layer3, type weight, shape (500, 800)\n",
      "Layer layer3, type bias, shape (500,)\n",
      "Layer layer4, type weight, shape (10, 500)\n",
      "Layer layer4, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "#print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcatFuNhe1fY"
   },
   "source": [
    "## Visualize hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6lxIEFReMxL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.children at 0x7f4becba2d50>\n"
     ]
    }
   ],
   "source": [
    "print(model.children())\n",
    "out = list(model.children())[0](img.cuda()).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rd-AKLbeL-A"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for _ in range(out.shape[1]):\n",
    "  plt.figure(figsize=(1, 1))\n",
    "  plt.imshow(out[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight, layer1.bias, layer2.weight, layer2.bias, layer3.weight, layer3.bias, layer4.weight, layer4.bias\n"
     ]
    }
   ],
   "source": [
    "print(', '.join([ k for (k, _) in params ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path = \"/content/drive/My Drive/Colab Notebooks/Falcon Neural Network/LeNet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"./preload/LeNet/\"\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].data.cpu().view(-1))\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer4_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[3].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(5*5*1, 20).tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].reshape(5*5*20, 50).tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())\n",
    "np.savetxt(fname=path+\"weight4_0\", delimiter=\" \", X=params[6][1].tolist())\n",
    "np.savetxt(fname=path+\"bias4_0\", delimiter=\" \", X=params[7][1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 975,    0,    0,    0,    0,    0,    1,    2,    2,    0],\n",
       "        [   0, 1133,    0,    0,    0,    0,    1,    1,    0,    0],\n",
       "        [   1,    1, 1024,    0,    2,    0,    0,    2,    2,    0],\n",
       "        [   0,    0,    1, 1004,    0,    2,    0,    1,    1,    1],\n",
       "        [   1,    0,    1,    0,  972,    0,    1,    2,    0,    5],\n",
       "        [   2,    0,    0,    7,    0,  879,    1,    1,    1,    1],\n",
       "        [   4,    2,    0,    1,    1,    2,  946,    0,    2,    0],\n",
       "        [   0,    3,    3,    1,    0,    0,    0, 1018,    1,    2],\n",
       "        [   2,    0,    1,    2,    0,    2,    0,    2,  963,    2],\n",
       "        [   0,    2,    0,    1,    4,    2,    0,    3,    0,  997]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some run on the network\n",
    "first = True\n",
    "act = []\n",
    "prd = []\n",
    "for (img, labels) in test_loader:\n",
    "    # Get the prediction\n",
    "    res = model(img.cuda())\n",
    "\n",
    "    # Get the label\n",
    "    label = np.array([[1 if i == l else 0 for i in range(10)] for l in labels])\n",
    "\n",
    "    # Write the batch\n",
    "    if first:\n",
    "        mode = \"w\"\n",
    "        first = False\n",
    "    else:\n",
    "        mode = \"a\"\n",
    "    with open(\"./results/LeNet_gold.txt\", mode) as h:\n",
    "        np.savetxt(h, delimiter=\" \", X=label.tolist())\n",
    "    with open(\"./results/LeNet_pred.txt\", mode) as h:\n",
    "        np.savetxt(h, delimiter=\" \", X=res.tolist())\n",
    "\n",
    "    # Add the class numbers\n",
    "    act += labels\n",
    "    prd += [ np.argmax(out.cpu().detach().numpy()) for out in res ]\n",
    "\n",
    "# Compute the things\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "confmat(torch.tensor(prd), torch.tensor(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_LeNet.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
