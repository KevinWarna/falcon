{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9625a6ee",
   "metadata": {},
   "source": [
    "Helper files from: \n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models\n",
    "\n",
    "\n",
    "AlexNet model settings and training from:\n",
    "- Github specific file: https://github.com/l5shi/Image-Recognition-on-MNIST-dataset/blob/master/AlexNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22258648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedb4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "# Deterministic behavior not yet supported by AdaptiveAvgPool2d\n",
    "#set_deterministic()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\") # to include ../helper_evaluate.py etc.\n",
    "\n",
    "from helper_evaluate import compute_accuracy\n",
    "from helper_data import get_dataloaders_mnist\n",
    "from helper_train import train_classifier_simple_v1\n",
    "\n",
    "### Set random seed ###\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bba886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "tensor([8, 3, 7, 7, 4, 7, 5, 4, 3, 7])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "tensor([0, 3, 7, 6, 1, 4, 2, 2, 0, 9])\n",
      "\n",
      "Testing Set:\n",
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "tensor([9, 3, 0, 3, 4, 2, 5, 1, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Dataset\n",
    "##########################\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomCrop((28, 28)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop((28, 28)),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_mnist (\n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=2, \n",
    "    train_transforms=train_transforms,\n",
    "    test_transforms=test_transforms,\n",
    "    validation_fraction=0.1)\n",
    "\n",
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    print(labels[:10])\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    print(labels[:10])\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    print(labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791d8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):   \n",
    "    def __init__(self, num=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),   \n",
    "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),                         \n",
    "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),                         \n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d( kernel_size=2, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32*12*12,2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,num),\n",
    "         \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.feature(x)\n",
    "        x = x.view(-1,32*12*12)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff6af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             832\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "            Conv2d-3           [-1, 64, 26, 26]          18,496\n",
      "              ReLU-4           [-1, 64, 26, 26]               0\n",
      "         MaxPool2d-5           [-1, 64, 13, 13]               0\n",
      "            Conv2d-6           [-1, 96, 13, 13]          55,392\n",
      "              ReLU-7           [-1, 96, 13, 13]               0\n",
      "            Conv2d-8           [-1, 64, 13, 13]          55,360\n",
      "              ReLU-9           [-1, 64, 13, 13]               0\n",
      "           Conv2d-10           [-1, 32, 13, 13]          18,464\n",
      "             ReLU-11           [-1, 32, 13, 13]               0\n",
      "        MaxPool2d-12           [-1, 32, 12, 12]               0\n",
      "           Linear-13                 [-1, 2048]       9,439,232\n",
      "             ReLU-14                 [-1, 2048]               0\n",
      "           Linear-15                 [-1, 1024]       2,098,176\n",
      "             ReLU-16                 [-1, 1024]               0\n",
      "           Linear-17                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 11,696,202\n",
      "Trainable params: 11,696,202\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.65\n",
      "Params size (MB): 44.62\n",
      "Estimated Total Size (MB): 46.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = AlexNet()\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55289734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd1fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/040 | Batch 0000/0210 | Loss: 2.3029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m log_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier_simple_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mlogging_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UvA/WORK/2.COMPARATIVE PAPER/falcon/scripts/MNIST_AlexNet/helper_train.py:51\u001b[0m, in \u001b[0;36mtrain_classifier_simple_v1\u001b[0;34m(num_epochs, model, optimizer, device, train_loader, valid_loader, loss_fn, logging_interval, skip_epoch_stats)\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# LOGGING\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m log_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_per_batch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m logging_interval:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m%03d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%03d\u001b[39;00m\u001b[38;5;124m | Batch \u001b[39m\u001b[38;5;132;01m%04d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%04d\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     55\u001b[0m           \u001b[38;5;241m%\u001b[39m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, num_epochs, batch_idx,\n\u001b[1;32m     56\u001b[0m               \u001b[38;5;28mlen\u001b[39m(train_loader), loss))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_dict = train_classifier_simple_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                                      optimizer=optimizer, device=device, \n",
    "                                      train_loader=train_loader, valid_loader=valid_loader, \n",
    "                                      logging_interval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    train_acc = compute_accuracy(model=model,\n",
    "                                 data_loader=test_loader,\n",
    "                                 device=device)\n",
    "    \n",
    "    test_acc = compute_accuracy(model=model,\n",
    "                                data_loader=test_loader,\n",
    "                                device=device)\n",
    "    \n",
    "    valid_acc = compute_accuracy(model=model,\n",
    "                                 data_loader=valid_loader,\n",
    "                                 device=device)\n",
    "    \n",
    "\n",
    "print(f'Train ACC: {valid_acc:.2f}%')\n",
    "print(f'Validation ACC: {valid_acc:.2f}%')\n",
    "print(f'Test ACC: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28151a21",
   "metadata": {},
   "source": [
    "# EXTRACT WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0964c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cecacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../files/preload/MNIST/AlexNet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02223c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight1_0\n",
      "weight1_1\n",
      "weight1_2\n",
      "bias1_0\n",
      "bias1_1\n",
      "bias1_2\n",
      "weight3_0\n",
      "weight3_1\n",
      "weight3_2\n",
      "bias3_0\n",
      "bias3_1\n",
      "bias3_2\n",
      "weight6_0\n",
      "weight6_1\n",
      "weight6_2\n",
      "bias6_0\n",
      "bias6_1\n",
      "bias6_2\n",
      "weight8_0\n",
      "weight8_1\n",
      "weight8_2\n",
      "bias8_0\n",
      "bias8_1\n",
      "bias8_2\n",
      "weight10_0\n",
      "weight10_1\n",
      "weight10_2\n",
      "bias10_0\n",
      "bias10_1\n",
      "bias10_2\n",
      "weight2_0\n",
      "weight2_1\n",
      "weight2_2\n",
      "bias2_0\n",
      "bias2_1\n",
      "bias2_2\n",
      "weight5_0\n",
      "weight5_1\n",
      "weight5_2\n",
      "bias5_0\n",
      "bias5_1\n",
      "bias5_2\n",
      "weight7_0\n",
      "weight7_1\n",
      "weight7_2\n",
      "bias7_0\n",
      "bias7_1\n",
      "bias7_2\n"
     ]
    }
   ],
   "source": [
    "for i in params:\n",
    "    name = i[0].split(\".\")\n",
    "    for ii in range(3):\n",
    "        file_name = name[2]+str(int(name[1])+1)+\"_\"+str(ii)\n",
    "        np.savetxt(fname=f\"{path}/{file_name}\", delimiter=\" \", X=i[1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write the used inputs and outputs\n",
    "#np.savetxt(fname=f\"{path}/input_0\", delimiter=\" \", X=images.cuda().view(-1, 3 * 33 * 33).tolist())\n",
    "#np.savetxt(fname=f\"{path}/outputlayer8_0\", delimiter=\" \", X=model.output(images.cuda().view(-1, 3, 33, 33)).data.cpu().view(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
